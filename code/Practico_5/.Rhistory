geom_line(mapping = aes(x=date, y=aod_380.y, color="#67000d"))
ggplot(dataset_comp_BA) +  geom_line(mapping = aes(x=date, y=aod_380.x, c="#fb6a4a"))+
geom_line(mapping = aes(x=date, y=aod_380.y, color="#67000d"))
ggplot(dataset_comp_BA) +  geom_line(mapping = aes(x=date, y=aod_380.x),c="#fb6a4a")+
geom_line(mapping = aes(x=date, y=aod_380.y), color="#67000d")
ggplot(dataset_comp_BA) +  geom_line(mapping = aes(x=date, y=aod_380.x),color="#fb6a4a")+
geom_line(mapping = aes(x=date, y=aod_380.y), color="#67000d")
ggplot(dataset_comp_BA) +  geom_line(mapping = aes(x=date, y=aod_380.x),color="#fb6a4a")+
geom_line(mapping = aes(x=date, y=aod_380.y), color="#67000d")+ legend()
ggplot(dataset_comp_BA) +  geom_line(mapping = aes(x=date, y=aod_380.x),color="#fb6a4a")+
geom_line(mapping = aes(x=date, y=aod_380.y), color="#67000d")+ theme_bw()
ggplot(dataset_comp_BA) +  geom_line(mapping = aes(x=date, y=aod_380.x),color="#fb6a4a")+
geom_line(mapping = aes(x=date, y=aod_380.y), color="#67000d")+theme_bw()+
ylab("AOD 380")
ggplot(dataset_comp_BA) +  geom_line(mapping = aes(x=date, y=aod_380.x),color="#fb6a4a")+
geom_line(mapping = aes(x=date, y=aod_380.y,color="L1.5"), color="#67000d")+theme_bw()+
ylab("AOD 380")
ggplot(dataset_comp_BA) +  geom_line(mapping = aes(x=date, y=aod_380.x),color="#fb6a4a")+
geom_line(mapping = aes(x=date, y=aod_380.y,group ="L1.5"), color="#67000d")+theme_bw()+
ylab("AOD 380")
ggplot(dataset_comp_BA) +  geom_line(mapping = aes(x=date, y=aod_380.x),color="#fb6a4a")+
geom_line(mapping = aes(x=date, y=aod_380.y,group ="L1.5"),show.legend = TRUE, color="#67000d")+theme_bw()+
ylab("AOD 380")
ggplot(dataset_comp_BA) +  geom_line(mapping = aes(x=date, y=aod_380.x),color="#fb6a4a")+
geom_line(mapping = aes(x=date, y=aod_380.y),show.legend = TRUE, color="#67000d")+theme_bw()+
ylab("AOD 380")+theme(legend.position = "top")
ggplot(dataset_comp_BA) +  geom_line(mapping = aes(x=date, y=aod_380.x,color="Y"),color="#fb6a4a")+
geom_line(mapping = aes(x=date, y=aod_380.y),show.legend = TRUE, color="#67000d")+theme_bw()+
ylab("AOD 380")+theme(legend.position = "top")
ggplot(dataset_comp_BA) +  geom_line(mapping = aes(x=date, y=aod_380.x,color="Y"))+
geom_line(mapping = aes(x=date, y=aod_380.y),show.legend = TRUE, color="#67000d")+theme_bw()+
ylab("AOD 380")+theme(legend.position = "top")
ggplot(dataset_comp_BA) +  geom_line(mapping = aes(x=date, y=aod_380.x,color="X"),show.legend = TRUE,color="#fb6a4a")+
geom_line(mapping = aes(x=date, y=aod_380.y,color="Y"),show.legend = TRUE, color="#67000d")+theme_bw()+
ylab("AOD 380")+theme(legend.position = "top")
ggplot(dataset_comp_BA) +  geom_line(mapping = aes(x=date, y=aod_380.x,color="X"),show.legend = TRUE)+
geom_line(mapping = aes(x=date, y=aod_380.y,color="Y"),show.legend = TRUE)+theme_bw()+
ylab("AOD 380")+theme(legend.position = "top")
ggplot(dataset_comp_BA) +  geom_line(mapping = aes(x=date, y=aod_380.x,c="X"),show.legend = TRUE)+
geom_line(mapping = aes(x=date, y=aod_380.y,color="Y"),show.legend = TRUE)+theme_bw()+
ylab("AOD 380")+theme(legend.position = "top")
ggplot(dataset_comp_BA) +  geom_line(mapping = aes(x=date, y=aod_380.x,colour="X"),show.legend = TRUE)+
geom_line(mapping = aes(x=date, y=aod_380.y,color="Y"),show.legend = TRUE)+theme_bw()+
ylab("AOD 380")+theme(legend.position = "top")
ggplot(dataset_comp_BA) +  geom_line(mapping = aes(x=date, y=aod_380.x,dataset="X"),show.legend = TRUE)+
geom_line(mapping = aes(x=date, y=aod_380.y,color="Y"),show.legend = TRUE)+theme_bw()+
ylab("AOD 380")+theme(legend.position = "top")
ggplot(dataset_comp_BA) +  geom_line(mapping = aes(x=date, y=aod_380.x,color="X"),show.legend = TRUE)+
geom_line(mapping = aes(x=date, y=aod_380.y,color="Y"),show.legend = TRUE)+theme_bw()+
ylab("AOD 380")+theme(legend.position = "top")
ggplot(dataset_comp_BA) +  geom_line(mapping = aes(x=date, y=aod_380.x,color="L2.0"),show.legend = TRUE)+
geom_line(mapping = aes(x=date, y=aod_380.y,color="L1.5"),show.legend = TRUE)+theme_bw()+
ylab("AOD 380")
ggplot(dataset_comp_BA) +  geom_line(mapping = aes(x=date, y=aod_380.x,color="L1.5"),show.legend = TRUE)+
geom_line(mapping = aes(x=date, y=aod_380.y,color="L2.0"),show.legend = TRUE)+theme_bw()+
ylab("AOD 380")
ggplot(dataset_comp_BA) +
geom_line(mapping = aes(x=date, y=aod_380.y,color="L2.0"),show.legend = TRUE)+theme_bw()+
geom_line(mapping = aes(x=date, y=aod_380.x,color="L1.5"),show.legend = TRUE)+
ylab("AOD 380")
nuevo <- 4071
viejo <-2818
(nuevo - viejo )/ viejo * 100
nuevo <- 4298
nuevo <- 4298
viejo <-2946
(nuevo - viejo )/ viejo * 100
nuevo <- 4404
viejo <-2998
(nuevo - viejo )/ viejo * 100
nuevo <- 4488
viejo <-3033
(nuevo - viejo )/ viejo * 100
((nuevo - viejo )/ viejo) * 100
(2818+2946+2998+3033)
4071+4298+4404+4488
nuevo <- 17261
viejo <- 11795
((nuevo - viejo )/ viejo) * 100
(4071+4298+4404+4488)/4
(2818+2946+2998+3033)/4
nuevo <- 4315
viejo <- 2948
((nuevo - viejo )/ viejo) * 100
nuevo <- 3605
viejo <- 2568
((nuevo - viejo )/ viejo) * 100
min_5_1km <- 2818
min_5_3km <- 2946
min_5_5km <-2998
min_5_9km <-3033
min_15_1km <-4071
min_15_3km <-4298
min_15_5km <-4404
min_15_9km <-4488
min_30_1km <-4295
min_30_3km <-4577
min_30_5km <-4716
min_30_9km <-4852
((min_15_1km - min_30_1km)/min_15_1km)*100
((-min_30_1km-min_15_1km)/min_15_1km)*100
((min_30_1km-min_15_1km)/min_15_1km)*100
((min_30_3km-min_15_3km)/min_15_3km)*100
((min_30_5km-min_15_5km)/min_15_5km)*100
((min_30_9km-min_15_9km)/min_15_9km)*100
min_5_1km_cal <- 2568
min_5_3km_cal <-2690
min_5_5km_cal <-2720
min_5_9km_cal <-2748
min_15_1km_cal <-3605
min_15_3km_cal <-3808
min_15_5km_cal <-3861
min_15_9km_cal <-3917
min_30_1km_cal <-3777
min_30_3km_cal <-4021
min_30_5km_cal <-4087
min_30_9km_cal <-4165
((min_15_1km_cal - min_5_1km_cal ) /min_5_1km_cal)*100
((min_30_1km_cal - min_15_1km_cal ) /min_15_1km_cal)*100
((min_30_3km_cal - min_15_3km_cal ) /min_15_3km_cal)*100
((min_30_3km_cal - min_15_3km_cal ) /min_15_3km_cal)*100
((min_30_3km_cal / min_15_3km_cal ) *100
((min_30_3km_cal / min_15_3km_cal ) *100)
((min_30_3km_cal - min_15_3km_cal ) /min_15_3km_cal)*100
((min_30_3km_cal / min_15_3km_cal ) *100) - 100
((min_15_3km_cal - min_5_3km_cal ) /min_5_3km_cal)*100
((min_15_1km_cal - min_5_1km_cal ) /min_5_1km_cal)*100
((min_15_3km_cal - min_5_3km_cal ) /min_5_3km_cal)*100
((min_15_5km_cal - min_5_5km_cal ) /min_5_5km_cal)*100
((min_15_9km_cal - min_5_9km_cal ) /min_5_9km_cal)*100
((min_30_1km_cal - min_5_1km_cal ) /min_5_1km_cal)*100
((min_30_3km_cal - min_5_3km_cal ) /min_5_3km_cal)*100
((min_30_5km_cal - min_5_5km_cal ) /min_5_5km_cal)*100
((min_30_9km_cal - min_5_9km_cal ) /min_5_9km_cal)*100
((min_30_1km_cal - min_15_1km_cal ) /min_15_1km_cal)*100
((min_30_3km_cal - min_15_3km_cal ) /min_15_3km_cal)*100
((min_30_5km_cal - min_15_5km_cal ) /min_15_5km_cal)*100
((min_30_9km_cal - min_15_9km_cal ) /min_15_9km_cal)*100
((min_15_1km - min_5_1km ) /min_5_1km_)*100
((min_15_1km - min_5_1km ) /min_5_1km)*100
((min_15_3km - min_5_3km ) /min_5_3km)*100
((min_15_5km - min_5_5km ) /min_5_5km)*100
((min_15_9km - min_5_9km ) /min_5_9km)*100
((min_30_1km - min_15_1km) /min_15_1km)*100
((min_30_3km - min_15_3km) /min_15_3km)*100
((min_30_5km- min_15_5km) /min_15_5km)*100
((min_30_9km- min_15_9km ) /min_15_9km)*100
min_5_1km_al <-1596
min_5_3km_al <-1859
min_5_5km_al <-1978
min_5_9km_al <-2087
min_15_1km_al <-2427
min_15_3km_al <-2889
min_15_5km_al <-3116
min_15_9km_al <-3462
min_30_1km_al <-2664
min_30_3km_al <-3250
min_30_5km_al <-3561
min_30_9km_al <-3903
#alemania
((min_15_1km_al - min_5_1km_al ) /min_5_1km_al)*100
((min_15_3km_al - min_5_3km_al ) /min_5_3km_al)*100
((min_15_5km_al - min_5_5km_al ) /min_5_5km_al)*100
((min_15_9km_al - min_5_9km_al ) /min_5_9km_al)*100
((min_30_1km_al - min_15_1km_al ) /min_15_1km_al)*100
((min_30_3km_al - min_15_3km_al ) /min_15_3km_al)*100
((min_30_5km_al - min_15_5km_al ) /min_15_5km_al)*100
((min_30_9km_al - min_15_9km_al ) /min_15_9km_al)*100
((min_30_1km_al - min_15_1km_al ) /min_15_1km_al)*100
((min_30_3km_al - min_15_3km_al ) /min_15_3km_al)*100
((min_30_5km_al - min_15_5km_al ) /min_15_5km_al)*100
((min_30_9km_al - min_15_9km_al ) /min_15_9km_al)*100
2<5
((0.774-0.768)/0.768)*100
((0.774-0.768)/0.768)
((0.774-0.768)/0.768)*100/100
((0.774-0.768)/0.768)*100
((0.56-0.55)/0.55)*100
#| code-fold: true
#| code-summary: "Carga paquetes y funciones"
library(nlme)
library(dplyr)
library(ggplot2)
library(sf)
library(tmap)
resumir_modelo <- function(modelo) {
rmse <- function(modelo) {
sqrt(mean(modelo$residuals^2))
}
aic <- AIC(modelo)
bic <- BIC(modelo)
my_rmse <- rmse(modelo)
regresora <- paste(attr(modelo$terms,"term.labels"), collapse = ", ")
conCor <- ifelse(length(modelo$modelStruct), 'Si', 'No')
data.frame('Indice' = regresora,
'ConCorr' = conCor,
'AIC' = aic,
'BIC' = bic,
'RMSE' = my_rmse,
check.names = FALSE)
}
diferenciaNormalizada <- function(x, y) {
(x - y) / (x + y)
}
# tmap::tmap_options(basemap.server = c(
#   'Satelital' = leaflet::providers$Esri.WorldImagery,
#   'OSM' = leaflet::providers$OpenStreetMap))
## -------------------------------------------------------------------------------------------------------------------------------------------------
setwd("D:/Josefina/Cursos/curso_gulich/analisis_espacial/code/Practico_5")
datos <- read.table("data/No_quemadas.txt")
## -------------------------------------------------------------------------------------------------------------------------------------------------
datos <- datos |>
mutate(
ndvi = diferenciaNormalizada(Banda4, Banda3),
gndvi = diferenciaNormalizada(Banda4, Banda2),
nci = diferenciaNormalizada(Banda5, Banda2)
)
## -------------------------------------------------------------------------------------------------------------------------------------------------
datos_sf <-
sf::st_as_sf(datos,
coords = c('X_coord', 'Y_coord'),
crs = 32720)
tmap_mode('view')
## -------------------------------------------------------------------------------------------------------------------------------------------------
tm_shape(datos_sf) +
tm_dots(fill = 'TCH',
fill.scale = tm_scale_continuous(values = "carto.ag_grn_yl"),
size = 0.5)
## -------------------------------------------------------------------------------------------------------------------------------------------------
tm_shape(datos_sf) +
tm_dots(fill = 'ndvi',
fill.scale = tm_scale_continuous(values = "tableau.classic_green"),
size = 0.5)
## -------------------------------------------------------------------------------------------------------------------------------------------------
#| fig-subcap: ["Histograma", "Gráfico de cajas"]
#| layout-ncol: 2
ggplot(datos, aes(TCH)) +
geom_histogram(aes(y = after_stat(count / sum(count))),
bins = 15) +
labs(y = 'Frecuencia Relativa')
ggplot(datos, aes(EDAD, TCH)) +
geom_boxplot(width = 0.25)
## -------------------------------------------------------------------------------------------------------------------------------------------------
#| label: fig-ndvi
#| fig-cap: "TCH en función de NDVI"
#| column: margin
#| echo: true
ggplot(datos, aes(ndvi, TCH)) +
geom_point()
summary(modelo_ndvi)
## -------------------------------------------------------------------------------------------------------------------------------------------------
# modelo lineal
#variable regresora es el nvdi
# yo quiero predecir TCH
#LM es un modelo lineal, el gls tambien ajusta lm pero con
# REML que es maxima versolsimilitud
# en cambio el lm ajusta con minimos cuadrada
# es un Generalized least squares fit by REML/ modelo generalizado
modelo_ndvi <- gls(TCH ~ ndvi,
data = datos,
method = 'REML')
## -------------------------------------------------------------------------------------------------------------------------------------------------
#| label: fig-gndvi
#| fig-cap: "TCH en función de gNDVI"
#| column: margin
#| echo: true
ggplot(datos, aes(gndvi, TCH)) +
geom_point()
## -------------------------------------------------------------------------------------------------------------------------------------------------
modelo_gndvi <- gls(TCH ~ gndvi,
data = datos,
method = 'REML')
summary(modelo_gndvi)
## -------------------------------------------------------------------------------------------------------------------------------------------------
#| label: fig-nci
#| fig-cap: "TCH en función de NCI"
#| column: margin
#| echo: true
ggplot(datos, aes(nci, TCH)) +
geom_point()
## -------------------------------------------------------------------------------------------------------------------------------------------------
# el reml es la funcion de enlace REML
modelo_nci <-  gls(TCH ~ nci,
data = datos,
method = 'REML')
summary(modelo_nci)
## -------------------------------------------------------------------------------------------------------------------------------------------------
# comparamos los 3 modelos, el mejorcito es el GNDVI, el que
# tiene menores valores
# el no significa que no tiene correlacion espacial
rbind(
resumir_modelo(modelo_ndvi),
resumir_modelo(modelo_gndvi),
resumir_modelo(modelo_nci)
)
modelo_ndvi_conCorr <- gls(
TCH ~ ndvi,
# Igual que antes pero le decimos que los residuos estan correlacionados
# funcion exponencial, considerando x e y
#ajustamos con correlacion espacial
correlation = corExp(
form =  ~ as.numeric(as.character(X_coord)) +
as.numeric(as.character(Y_coord)),
metric = "euclidean",
nugget = FALSE# que no calcule el  nugget, lo ideal es probar con/sin nugget
#cual es el mejor. Cual es la variabilidad a escala menor
),
data = datos,
method = 'REML'
)
summary(modelo_ndvi_conCorr)
## -------------------------------------------------------------------------------------------------------------------------------------------------
#| label: modelo-corr-gndvi
modelo_gndvi_conCorr <- gls(
TCH ~ gndvi,
correlation = corExp(
form =  ~ as.numeric(as.character(X_coord)) +
as.numeric(as.character(Y_coord)),
metric = "euclidean",
nugget = FALSE
),
data = datos,
method = 'REML'
)
summary(modelo_gndvi_conCorr)
## -------------------------------------------------------------------------------------------------------------------------------------------------
#| label: modelo-corr-nci
modelo_nci_conCorr <- gls(
TCH ~ nci,
correlation = corExp(
form =  ~ as.numeric(as.character(X_coord)) +
as.numeric(as.character(Y_coord)),
metric = "euclidean",
nugget = FALSE
),
data = datos,
method = 'REML'
)
summary(modelo_nci_conCorr)
## -------------------------------------------------------------------------------------------------------------------------------------------------
# dismunye el error con correlacion espacial, el mejor ajuste es
# el gndvi que contempla una estructura espacial de los residuos es decil del error
rbind(
resumir_modelo(modelo_ndvi),
resumir_modelo(modelo_ndvi_conCorr),
resumir_modelo(modelo_gndvi),
resumir_modelo(modelo_gndvi_conCorr),
resumir_modelo(modelo_nci),
resumir_modelo(modelo_nci_conCorr)
)
## -------------------------------------------------------------------------------------------------------------------------------------------------
ef_fijos_ndvo_iid <- summary(modelo_ndvi)
ef_fijos_ndvo_iid$tTable
## -------------------------------------------------------------------------------------------------------------------------------------------------
ef_fijos_ndvo_corr <- summary(modelo_ndvi_conCorr)
ef_fijos_ndvo_corr$tTable
predichos_lm <- datos
predichos_lm$pred_ndvi_iid <- predict(modelo_ndvi)
predichos_lm$pred_ndvi_esp <- predict(modelo_ndvi_conCorr)
ggplot(predichos_lm, aes(pred_ndvi_iid, TCH)) +
geom_point() +
geom_abline(slope = 1, intercept = 0)
ggplot(predichos_lm, aes(pred_ndvi_esp, TCH)) +
geom_point() +
geom_abline(slope = 1, intercept = 0)
ggplot(predichos_lm, aes(pred_ndvi_esp, pred_ndvi_iid)) +
geom_point() +
geom_abline(slope = 1, intercept = 0)
# if (!requireNamespace("BiocManager", quietly = TRUE))
#   install.packages("BiocManager")
# BiocManager::install(c("graph", "Rgraphviz"), dep = TRUE)
#
#  install.packages(
#    "INLA",
#    repos = c(getOption("repos"), INLA = "https://inla.r-inla-download.org/R/testing"),
#    dep = TRUE
# )
# https://www.r-inla.org/download-install
library(INLA)
library(inlabru)
## -------------------------------------------------------------------------------------------------------------------------------------------------
inla.setOption(inla.mode = 'experimental')
loc <- st_coordinates(datos_sf)
# Esta es la grilla de datos geoestadisticos
# se mueve en un continuo
# lattice seria por ejemplo calcula datos del rendimiento de cada provincia
# un poligono seria unlattice, y tiene vecinos
mesh <- INLA::inla.mesh.2d( # mesh es la grilla
loc = loc,
offset = c(1000, 4000),# de la linea azul
cutoff = 800,# de la linea negra
max.edge = c(1000, 2000),
max.n = 10000)
# La prediccion se hace sobre todo y despues puedo recortar
# esto es mas que nada por el efecto de los bordes
ggplot(datos_sf) +
gg(mesh) +
geom_sf()
# le tenemos que especificar los parametros a priori
# antes en krigging haciamos un semivariograma. Pero aca no sabemos
# lo "inventamos" a ojo
# le asocio un rango y una varianza especifica. Hasta donde estan correlacionados los datos
spde <- INLA::inla.spde2.pcmatern(
mesh = mesh,
#como tengo 2 valores en el () significa que no es fijo el sigma del rango, si no que es variable
prior.range = c(2000, 0.05),#rango
prior.sigma = c(200, 0.01)#varianza, 0.01 distribucion/un rango de probabilidad
)
## ----ajuste-inlabru-------------------------------------------------------------------------------------------------------------------------------
#| column: page-right
#| layout-align: center
#|
ndvi_bru_spde <-
bru( # usamos inlabru,
# interce
# site significa un efecto sitio que debente de las coordenadas y del modelo generado antes esto es los valores aleatorios
# sin el site
TCH ~ Intercept(1) + ndvi + site(main = coordinates, model = spde),
family = "gaussian", # asumimos que el tch tiene una distribucion normal
data = as_Spatial(datos_sf) # inla permite objetos espaciales por eso sf, pero los tenemos qe pasar a sp
)
summary(ndvi_bru_spde)
## -------------------------------------------------------------------------------------------------------------------------------------------------
#| column: screen-inset-shaded
#| layout-nrow: 1
plot(ndvi_bru_spde, "Intercept")
plot(ndvi_bru_spde, "ndvi")
spde.posterior(ndvi_bru_spde, "site", what = "matern.covariance") -> covplot
spde.posterior(ndvi_bru_spde, "site", what = "matern.correlation") -> corplot
spde.posterior(ndvi_bru_spde, "site", what = "range") -> rngplot
spde.posterior(ndvi_bru_spde, "site", what = "log.range") -> lgrngplot
spde.posterior(ndvi_bru_spde, "site", what = "variance") -> varplot
spde.posterior(ndvi_bru_spde, "site", what = "log.variance") -> lgvarplot
multiplot(plot(covplot), plot(corplot),
plot(rngplot), plot(lgrngplot),
plot(varplot), plot(lgvarplot))
## -------------------------------------------------------------------------------------------------------------------------------------------------
# hago la prediccion cpnsiderando varios parametros
pred_mesh <-
predict(ndvi_bru_spde, as_Spatial(datos_sf), ~ Intercept + ndvi + site)
# como es u n objeto sp lo pasamos a st
predichos <- st_as_sf(pred_mesh)
ggplot(predichos, aes(mean, TCH)) +
geom_point() +
geom_abline(slope = 1, intercept = 0)
predichos
# como es u n objeto sp lo pasamos a st
predichos <- st_as_sf(pred_mesh)
ggplot(predichos, aes(mean, TCH)) +
geom_point() +
geom_abline(slope = 1, intercept = 0)
## -------------------------------------------------------------------------------------------------------------------------------------------------
predichos_lm$pred_ndvi_inla <- predichos$mean
ggplot(predichos_lm, aes(pred_ndvi_iid, TCH)) +
geom_point() +
geom_abline(slope = 1, intercept = 0)
ggplot(predichos_lm, aes(pred_ndvi_esp, TCH)) +
geom_point() +
geom_abline(slope = 1, intercept = 0)
ggplot() +
geom_point(data = predichos_lm,
aes(pred_ndvi_iid, TCH, color = 'REML iid')) +
geom_point(data = predichos_lm,
aes(pred_ndvi_esp, TCH, color = 'REML Corr')) +
geom_point(data = predichos_lm,
aes(pred_ndvi_inla, TCH, color = 'INLA Corr')) +
geom_abline(slope = 1, intercept = 0) +
labs(x = 'TCH Predichos', y = 'TCH Observado', color = 'Estimación')
ggplot() +
geom_point(data = predichos_lm,
aes(pred_ndvi_iid, TCH, color = 'REML iid')) +
geom_point(data = predichos_lm,
aes(pred_ndvi_esp, TCH, color = 'REML Corr')) +
geom_point(data = predichos_lm,
aes(pred_ndvi_inla, TCH, color = 'INLA Corr')) +
geom_abline(slope = 1, intercept = 0) +
labs(x = 'TCH Predichos', y = 'TCH Observado', color = 'Estimación')
## -------------------------------------------------------------------------------------------------------------------------------------------------
datos <- st_read("data/Base_07_07_radios.gpkg", quiet = TRUE)
## -------------------------------------------------------------------------------------------------------------------------------------------------
datos$E <- datos$Poblacion * sum(datos$Casos) / sum(datos$Poblacion)
# s modela la cantidad de casos de covid por radiocensales
## -------------------------------------------------------------------------------------------------------------------------------------------------
datos <- st_read("data/Base_07_07_radios.gpkg", quiet = TRUE)
## -------------------------------------------------------------------------------------------------------------------------------------------------
datos$E <- datos$Poblacion * sum(datos$Casos) / sum(datos$Poblacion)
## -------------------------------------------------------------------------------------------------------------------------------------------------
tm_shape(datos) +
tm_polygons(fill = 'E')
## -------------------------------------------------------------------------------------------------------------------------------------------------
datos$SIR <- datos$Casos / datos$E
## -------------------------------------------------------------------------------------------------------------------------------------------------
tm_shape(datos) +
tm_polygons(fill = 'SIR')
## -------------------------------------------------------------------------------------------------------------------------------------------------
datos$re_u <- 1:nrow(datos)
## -------------------------------------------------------------------------------------------------------------------------------------------------
datos$E <- datos$Poblacion * sum(datos$Casos) / sum(datos$Poblacion)
## -------------------------------------------------------------------------------------------------------------------------------------------------
tm_shape(datos) +
tm_polygons(fill = 'E')
datos$SIR <- datos$Casos / datos$E
## -------------------------------------------------------------------------------------------------------------------------------------------------
tm_shape(datos) +
tm_polygons(fill = 'SIR')
## -------------------------------------------------------------------------------------------------------------------------------------------------
datos$re_u <- 1:nrow(datos)
datos$re_v <- 1:nrow(datos)
## -------------------------------------------------------------------------------------------------------------------------------------------------
# Generación de lista con vecindarios
nb <- poly2nb(datos)
nb
