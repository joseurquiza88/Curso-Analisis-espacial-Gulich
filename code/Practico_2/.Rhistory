# como me da siempre el mismo peso /n
# lo vamos a ponderar segun la distancia
# entonces cada fila me va a dar =1
fdist <- lapply(dist, function(x)
(1 / (x / 100)))
lw2 <- nb2listw(vecindarios, glist = fdist, style = "W")
lw2$weights[10]
sum(lw2$weights[10][[1]])
lw2
#  Generación del Moran Plot (MP) ####
MP <-
moran.plot(
misdatos_2$REND,
lw2,# esto es una lista de los pesos, tambien podemos poner el lw
col = 3,
quiet = T,
labels = F,
zero.policy = T, # esto tambien lo pusimos antes
xlab = "Rendimiento",
ylab = "Rendimiento Spatially Lagged"
)
#  Generación del Moran Plot (MP) ####
MP <-
moran.plot(
misdatos_2$REND,
lw2,# esto es una lista de los pesos, tambien podemos poner el lw
col = 3,
quiet = T,
labels = F,
zero.policy = T, # esto tambien lo pusimos antes
xlab = "Rendimiento",
ylab = "Rendimiento Spatially Lagged"
)
head(MP)
Influ <- MP$is_inf
Influ
###################################################
##################################################
#  Cálculo del índice de Moran local (IML) ####
ML <-
localmoran(misdatos_2$REND, lw2, alternative = "less")
head(ML)
IMl <-
printCoefmat(data.frame(ML, row.names = misdatos_2$Casos), check.names =
FALSE)
#####################################################3
# el influ usamos que eran T o F
#  Eliminación de inliers utilizando IML y MP  ####
misdatos_3 <- cbind(misdatos_2, Influ, IMl)
head(misdatos_3)
#st_write(misdatos_3,"Datosadepurar.gpkg")
# Aca si eliminamos datos, me quedo aquellos que tengan
#indice de moran local + y no sean estadisticamente significatco
misdatos_3 <-
subset(misdatos_3, misdatos_3[["Ii"]] > 0 |
misdatos_3[["Pr.z...E.Ii.."]] > 0.05)
###################################################
##################################################
#  Cálculo del índice de Moran local (IML) ####
ML <-
localmoran(misdatos_2$REND, lw2, alternative = "less")
head(ML)
IMl <-
printCoefmat(data.frame(ML, row.names = misdatos_2$Casos), check.names =
FALSE)
head(IMl)
#####################################################3
# el influ usamos que eran T o F
#  Eliminación de inliers utilizando IML y MP  ####
# Aca solo unimos los dos DF
misdatos_3 <- cbind(misdatos_2, Influ, IMl)
head(misdatos_3)
#st_write(misdatos_3,"Datosadepurar.gpkg")
# Aca si eliminamos datos, me quedo aquellos que tengan
#indice de moran local + y no sean estadisticamente significatco
misdatos_3 <-
subset(misdatos_3, misdatos_3[["Ii"]] > 0 |
misdatos_3[["Pr.z...E.Ii.."]] > 0.05)
#Me quedo con los que son influyentes
# es decir me quedo con los datos que son similares
# en los vecindarios
misdatos_3 <- misdatos_3[misdatos_3$Influ == FALSE, ]
# Media, mediana y coeficiente de asimetría luego de eliminar outliers e inliers ####
(mean(misdatos_3$REND))
(median(misdatos_3$REND))
(e1071::skewness(misdatos_3$REND))
#  Histograma y gráfico box-plot luego de eliminar outliers e inliers ####
histograma_3 <- ggplot(misdatos_3, aes(x = REND)) +
geom_histogram(aes(y = after_stat(count) / sum(count))) +
ylab("Frecuencia Relativa") +
theme_light()
boxplot_3 <- ggplot(misdatos_3, aes(y = REND)) +
geom_boxplot() +
ylab("Rendimiento (t/ha)")  +
scale_x_discrete(breaks = NULL) +
xlab(NULL) +
theme_light()
grid.arrange(histograma_3, boxplot_3,
ncol = 2)
grid.arrange(histograma_3, boxplot_3,
ncol = 2)
#  Histograma y gráfico box-plot luego de eliminar outliers e inliers ####
histograma_3 <- ggplot(misdatos_3, aes(x = REND)) +
geom_histogram(aes(y = after_stat(count) / sum(count))) +
ylab("Frecuencia Relativa") +
theme_light()
boxplot_3 <- ggplot(misdatos_3, aes(y = REND)) +
geom_boxplot() +
ylab("Rendimiento (t/ha)")  +
scale_x_discrete(breaks = NULL) +
xlab(NULL) +
theme_light()
grid.arrange(histograma_3, boxplot_3,
ncol = 2)
grid.arrange(histograma_3, boxplot_3,
ncol = 2)
st_write(misdatos_3[, c("REND", "geom")], "soja_depurado.gpkg", delete_layer = T)
grid.arrange(histograma_3, boxplot_3,
ncol = 2)
grid.arrange(histograma_3, boxplot_3,
ncol = 2)
st_write(misdatos_3[, c("REND", "geom")], "soja_depurado.gpkg", delete_layer = T)
#  Gráfico de dispersión de la variable REND con coordenadas x e y  para la detección de tendencias ####
base_depurada <- cbind(misdatos_3, st_coordinates(misdatos_3))
#################33333
#  Gráfico de dispersión de la variable REND con coordenadas x e y  para la detección de tendencias ####
# Le agrego una columna con los datos de la coordenada
# st_coordinate devuelve un df con la geometria
base_depurada <- cbind(misdatos_3, st_coordinates(misdatos_3))
head(base_depurada)
# grafico de rendimiento vs longitud
px <- ggplot(base_depurada, aes(X, REND)) +
geom_point() +
geom_smooth(method = lm, se = FALSE)
# grafico de rendimiento vs latitud
py <- ggplot(base_depurada, aes(Y, REND)) +
geom_point() +
geom_smooth(method = lm, se = FALSE)
px
px
dev.off()
px
# dev.off()
grid.arrange(px, py, ncol = 2)
# vemos una leve tendencia en y
#segun el profe no seria significativa
regresion <-
lm(formula = REND ~ 1 + X + Y ,
data = base_depurada,
na.action = na.omit)
summary(regresion)
plot(
base_depurada[, "REND"],
key.pos = 4,
axes = TRUE,
key.width = lcm(1.5),
key.length = 1,
breaks = c(0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4)
)
plot(
base_depurada[, "REND"],
key.pos = 4,
axes = TRUE,
key.width = lcm(1.5),
key.length = 1,
pal = terrain.colors
)
# Carga de paquetes ####
library(sp)
library(spdep)
library(RColorBrewer)
library(mapview)
library(ggplot2)
library(spatstat)
# Carga de base de datos ####
datos_rinde <- st_read("soja_depurado.gpkg")
head(datos_rinde)
class(datos_rinde)
datos_MO <- read.table("MO_Córdoba.txt", header = T)
head(datos_MO)
# Transformación a objeto espacial y visualización ####
datos_MO <- st_as_sf(datos_MO, coords = c("x", "y"), crs = 22174)
class(datos_MO)
cols <- colorRampPalette(rev(brewer.pal(11, "Spectral")))
##########################################################
# esto es para indicde de moran global
# Definición de vecindarios ####
## Datos MO ####
vecindarios_MO <- dnearneigh(datos_MO$geometry, 0, 25000)
summary(vecindarios_MO)
vecindarios_MO[20]
plot(
vecindarios_MO,
datos_MO$geometry,
col = "#009999",
pch = 20,
cex = 1
)
# LOS VECINDARIOS
lw_MO <- nb2listw(vecindarios_MO, style = "W")
##########################################################
# esto es para indicde de moran global
# Definición de vecindarios ####
## Datos MO ####
vecindarios_MO <- dnearneigh(datos_MO$geometry, 0, 25000)
summary(vecindarios_MO)
vecindarios_MO[20]
# LOS VECINDARIOS
lw_MO <- nb2listw(vecindarios_MO, style = "W")
lw_MO
# Opción para contemplar observaciones sin vecindario
spdep::set.ZeroPolicyOption(TRUE)
lw_MO <- nb2listw(vecindarios_MO, style = "W")
lw_MO$weights[20]
## Datos MO ponderando por distancia ####
vecindarios_MO_p <- dnearneigh(datos_MO$geometry, 0, 25000)
summary(vecindarios_MO_p)
## Datos MO ponderando por distancia ####
vecindarios_MO_p <- dnearneigh(datos_MO$geometry, 0, 25000)
summary(vecindarios_MO_p)
vecindarios_MO_p[20]
dist <- spdep::nbdists(vecindarios_MO_p, datos_MO)
dist[20]
fdist <- lapply(dist, function(x)
(1 / (x / 100)))
lw_MO_p <-
try(spdep::nb2listw(vecindarios_MO_p, glist = fdist, style = "W"),
silent = TRUE)
lw_MO_p$weights[20]
## Datos Rendimiento ####
vecindarios_rinde <- dnearneigh(datos_rinde$geom, 0, 10)
summary(vecindarios_rinde)
plot(
vecindarios_rinde,
datos_rinde$geom,
col = "#009999",
pch = 20,
cex = 0.5
)
lw_rinde <-
nb2listw(vecindarios_rinde, style = "W", zero.policy = T)
imoran_rinde <-
moran.mc(datos_rinde$REND,
lw_rinde,
nsim = 1000,
zero.policy = T)
imoran_rinde
### Cálculo del índice de autocorrelación espacial de Moran
# hace 1000 permutaciones, hace
# no tiene en cuenta el valor espacial
#toma aleatoriamente valores, 1000 valores
plot(imoran_MO)
imoran_MO <-
moran.mc(datos_MO$MO, lw_MO_p, nsim = 1000, zero.policy = T)
### Cálculo del índice de autocorrelación espacial de Moran
# hace 1000 permutaciones, hace
# no tiene en cuenta el valor espacial
#toma aleatoriamente valores, 1000 valores
plot(imoran_MO)
imoran_rinde <-
moran.mc(datos_rinde$REND,
lw_rinde,
nsim = 1000,
zero.policy = T)
#################################################
### Cálculo del IM para multiples distancias
distancias <- function (dmax) {
vec <- dnearneigh(datos_MO, 0, dmax)
lw <- nb2listw(vec, style = "W")
i.moran <- moran.mc(datos_MO$MO, lw, nsim = 999, zero.policy =
T)
tabla <- data.frame("Distancia" = dmax, "MI" = i.moran$statistic)
tabla
}
tablad <-
do.call(rbind, lapply(c(
seq(15000, 40000, 1000), seq(45000, 80000, 5000)
), distancias))
tablad
# Esto nos va a servir para elegir la distancia
# vemos que el indice de moran sube pero a 24 km
# tiende a bajar. el valor seleccionado de 25 esta bien
# cuanto mayor sea el indice es mejor, es decir mas cercano a 1
#significa que hay autocorrelacion espacial
#####################################################
#######################################
# Patrones de Puntos ####
data(swedishpines)
summary(swedishpines)
plot(swedishpines)
data(bei)
summary(bei)
plot(bei)
data(urkiola)
summary(urkiola)
plot(urkiola)
datos <- bei
pendiente <- bei.extra$grad
plot(pendiente)
## Localización de puntos en el espacio ####
plot(datos,
pch = 20,
cols = "grey70",
main = "Localización de Árboles en un Bosque Tropical")
## Conteo por cuadrante ####
cuadrantes <- quadratcount(datos, nx = 5, ny = 5)
cuadrantes
#data_1.5 <- read.csv("D:/Josefina/Proyectos/aeronet/datos/ceilap.csv",header=TRUE, skip=6,sep=",", dec=".", na.strings = "-999", stringsAsFactors = FALSE )
data_1.5 <- read.csv("D:/Josefina/Proyectos/aeronet/comparacion_versiones_aeronet/dataset/BA-2015-2022-L15.csv",header=TRUE, sep=",", dec=".", na.strings = "-999", stringsAsFactors = FALSE )
data_1.5$date <- paste(data_1.5$Date.dd.mm.yyyy., data_1.5$Time.hh.mm.ss., sep=" ")
data_1.5$date <-strptime(data_1.5$date, format="%d:%m:%Y %H:%M:%S", tz="GMT")
data_1.5$date <- as.POSIXct(data_1.5$date, format="%Y-%m-%d %H:%M:%S", tz="GMT")
data_1.5$year<- substr(data_1.5$Date.dd.mm.yyyy.,7,10)
data_1.5$mes<- substr(data_1.5$Date.dd.mm.yyyy.,4,5)
data_1.5$year_mes <- paste(data_1.5$year,data_1.5$mes,sep="")
data_1.5_c <- data_frame(date = data_1.5$date,
year = data_1.5$year,
year_mes = data_1.5$year_mes,
aod_380 = data_1.5$AOD_380nm,
aod_440 = data_1.5$AOD_440nm,
aod_500 = data_1.5$AOD_500nm,
aod_670 = data_1.5$AOD_675nm,
aod_870 = data_1.5$AOD_870nm,
aod_1020 = data_1.5$AOD_1020nm)
data_2 <- read.csv("D:/Josefina/Proyectos/aeronet/comparacion_versiones_aeronet/dataset/BA-2015-2022-L20.csv",header=TRUE, sep=",", dec=".", na.strings = "-999", stringsAsFactors = FALSE )
data_2$date <- paste(data_2$Date.dd.mm.yyyy., data_2$Time.hh.mm.ss., sep=" ")
data_2$date <-strptime(data_2$date, format="%d:%m:%Y %H:%M:%S", tz="GMT")
data_2$date <- as.POSIXct(data_2$date, format="%Y-%m-%d %H:%M:%S", tz="GMT")
data_2$year<- substr(data_2$Date.dd.mm.yyyy.,7,10)
data_2$mes<- substr(data_2$Date.dd.mm.yyyy.,4,5)
data_2$year_mes <- paste(data_2$year,data_2$mes,sep="")
data_2_c <- data_frame(date = data_2$date,
year = data_2$year,
year_mes = data_2$year_mes,
aod_380 = data_2$AOD_380nm,
aod_440 = data_2$AOD_440nm,
aod_500 = data_2$AOD_500nm,
aod_670 = data_2$AOD_675nm,
aod_870 = data_2$AOD_870nm,
aod_1020 = data_2$AOD_1020nm)
View(data_1.5)
data_1.5_c$aod_380
length(data_1.5_c$aod_380)
length(data_1.5_c$aod_380,na.rm=T)
data_1.5_aod_380  <- filter(data_1.5_c$aod_380 != NA)
data_1.5_c$aod_380
data_1.5_aod_380  <- !is.na(data_1.5_c$aod_380)
data_1.5_aod_380  <- data.frame(!is.na(data_1.5_c$aod_380))
View(data_1.5_aod_380)
data_1.5_aod_380  <- data_1.5_c[data_1.5_c$aod_380 != is.na(data_1.5_c$aod_380)
data_1.5_aod_380  <- data_1.5_c[data_1.5_c$aod_380 != is.na(data_1.5_c$aod_380),]
View(data_1.5_aod_380)
data_1.5_aod_380  <-  data_1.5_c[complete.cases(data_1.5_c$), ]
data_1.5_aod_380  <-  data_1.5_c[complete.cases(data_1.5_c$aod_380), ]
data_1.5_aod_440  <-  data_1.5_c[complete.cases(data_1.5_c$aod_440), ]
data_1.5_aod_380  <-  data_1.5_c[complete.cases(data_1.5_c$aod_380), ]
data_1.5_aod_440  <-  data_1.5_c[complete.cases(data_1.5_c$aod_440), ]
data_1.5_aod_500  <-  data_1.5_c[complete.cases(data_1.5_c$aod_500), ]
data_1.5_aod_670  <-  data_1.5_c[complete.cases(data_1.5_c$aod_670), ]
data_1.5_aod_870  <-  data_1.5_c[complete.cases(data_1.5_c$aod_870), ]
data_1.5_aod_1020  <-  data_1.5_c[complete.cases(data_1.5_c$aod_1020), ]
data_1.5_aod_1020  <-  len(data_1.5_c[complete.cases(data_1.5_c$aod_1020), ])
data_1.5_aod_1020  <-  length(data_1.5_c[complete.cases(data_1.5_c$aod_1020), ])
data_1.5_aod_1020
data_1.5_aod_1020  <-  length(data_1.5_c[complete.cases(data_1.5_c$aod_1020), ][,1])
length(data_1.5_c[complete.cases(data_1.5_c$aod_1020), ][,1])
length(data_1.5_c[complete.cases(data_1.5_c$aod_1020)])
data_1.5_aod_1020  <-  length(data_1.5_c[complete.cases(data_1.5_c$aod_1020),][1])
data_1.5_aod_1020
length(data_1.5_c[complete.cases(data_1.5_c$aod_1020),][1,])
length(data_1.5_c[complete.cases(data_1.5_c$aod_1020),][,1])
length(data_1.5_c[complete.cases(data_1.5_c$aod_1020),][:1])
data_1.5_aod_1020  <-  data_1.5_c[complete.cases(data_1.5_c$aod_1020),]
View(data_1.5_aod_1020)
View(data_1.5_aod_1020[1])
data_1.5_aod_1020  <-  data_1.5_c[complete.cases(data_1.5_c$aod_1020),][1]
data_1.5_aod_1020
data_1.5_aod_1020  <-  data_1.5_c[complete.cases(data_1.5_c$aod_1020),][5]
data_1.5_aod_1020
length(data_1.5_c[complete.cases(data_1.5_c$aod_1020),][5])
length(data_1.5_c[complete.cases(data_1.5_c$aod_1020),][[5]])
# LO DIVIDIMOS POR MES
data_1.5_c$year_mes
data_1.5_c$year
# LO DIVIDIMOS POR año
data_1.5_c_2015 <- data_1.5_c[data_1.5_c$year == "2015",]
data_1.5_c_2015
data_2_c_2015 <- data_2_c[data_2_c$year == "2015",]
# LO DIVIDIMOS POR año
data_1.5_c_2015 <- data_1.5_c[data_1.5_c$year == "2015",]
length(data_1.5_c_2015$aod_380)
length(data_2_c_2015$aod_380)
length(data_1.5_c_2015[complete.cases(data_1.5_c_2015$aod_380), ][[5]])
length(data_2_c_2015[complete.cases(data_2_c_2015$aod_380), ][[5]])
#7253
length(data_1.5_c_2015[complete.cases(data_1.5_c_2015$aod_440), ][[5]])
#7253
length(data_2_c_2015[complete.cases(data_2_c_2015$aod_440), ][[5]])
## ------ AOD 500
#7264
length(data_1.5_c_2015[complete.cases(data_1.5_c_2015$aod_500), ][[5]])
#7264
length(data_2_c_2015[complete.cases(data_2_c_2015$aod_500), ][[5]])
## ------ AOD 670
#7262
length(data_1.5_c_2015[complete.cases(data_1.5_c_2015$aod_670), ][[5]])
#7262
length(data_2_c_2015[complete.cases(data_2_c_2015$aod_670), ][[5]])
## ------ AOD 870
#7263
length(data_1.5_c_2015[complete.cases(data_1.5_c_2015$aod_870), ][[5]])
#7263
length(data_2_c_2015[complete.cases(data_2_c_2015$aod_870), ][[5]])
## ------ AOD 1020
#7265
length(data_1.5_c_2015[complete.cases(data_1.5_c_2015$aod_1020), ][[5]])
#7265
length(data_2_c_2015[complete.cases(data_2_c_2015$aod_1020), ][[5]])
##################################################################
##                          2016!!!!
data_1.5_c_2016 <- data_1.5_c[data_1.5_c$year == "2016",]
data_2_c_2016 <- data_2_c[data_2_c$year == "2016",]
length(data_1.5_c_2016$aod_380) #7266
length(data_2_c_2016$aod_380)#7266
#7253
length(data_1.5_c_2016[complete.cases(data_1.5_c_2016$aod_380), ][[5]])
#7253
length(data_2_c_2016[complete.cases(data_2_c_2016$aod_380), ][[5]])
## ------ AOD 440
#7264
length(data_1.5_c_2016[complete.cases(data_1.5_c_2016$aod_440), ][[5]])
## ------ AOD 440
#2562
length(data_1.5_c_2016[complete.cases(data_1.5_c_2016$aod_440), ][[5]])
#7264
length(data_2_c_2016[complete.cases(data_2_c_2016$aod_440), ][[5]])
## ------ AOD 500
#7262
length(data_1.5_c_2016[complete.cases(data_1.5_c_2016$aod_500), ][[5]])
#7262
length(data_2_c_2016[complete.cases(data_2_c_2016$aod_500), ][[5]])
#2567
length(data_2_c_2016[complete.cases(data_2_c_2016$aod_500), ][[5]])
## ------ AOD 670
#7263
length(data_1.5_c_2016[complete.cases(data_1.5_c_2016$aod_670), ][[5]])
#7263
length(data_2_c_2016[complete.cases(data_2_c_2016$aod_670), ][[5]])
## ------ AOD 870
#7265
length(data_1.5_c_2016[complete.cases(data_1.5_c_2016$aod_870), ][[5]])
#7265
length(data_2_c_2016[complete.cases(data_2_c_2016$aod_870), ][[5]])
## ------ AOD 870
#2248
length(data_1.5_c_2016[complete.cases(data_1.5_c_2016$aod_870), ][[5]])
#2248
length(data_2_c_2016[complete.cases(data_2_c_2016$aod_870), ][[5]])
## ------ AOD 1020
#7255
length(data_1.5_c_2016[complete.cases(data_1.5_c_2016$aod_1020), ][[5]])
#7255
length(data_2_c_2016[complete.cases(data_2_c_2016$aod_1020), ][[5]])
##################################################################
##                          2017!!!!
data_1.5_c_2017 <- data_1.5_c[data_1.5_c$year == "2017",]
data_2_c_2017 <- data_2_c[data_2_c$year == "2017",]
length(data_1.5_c_2017$aod_380) #72568
length(data_2_c_2017$aod_380)#2568
#7253
length(data_1.5_c_2017[complete.cases(data_1.5_c_2017$aod_380), ][[5]])
#7253
length(data_2_c_2017[complete.cases(data_2_c_2017$aod_380), ][[5]])
## ------ AOD 440
#2562
length(data_1.5_c_2017[complete.cases(data_1.5_c_2017$aod_440), ][[5]])
#2562
length(data_2_c_2017[complete.cases(data_2_c_2017$aod_440), ][[5]])
## ------ AOD 500
#2567
length(data_1.5_c_2017[complete.cases(data_1.5_c_2017$aod_500), ][[5]])
#2567
length(data_2_c_2017[complete.cases(data_2_c_2017$aod_500), ][[5]])
## ------ AOD 670
#2567
length(data_1.5_c_2017[complete.cases(data_1.5_c_2017$aod_670), ][[5]])
#2567
length(data_2_c_2017[complete.cases(data_2_c_2017$aod_670), ][[5]])
## ------ AOD 870
#2248
length(data_1.5_c_2017[complete.cases(data_1.5_c_2017$aod_870), ][[5]])
#2248
length(data_2_c_2017[complete.cases(data_2_c_2017$aod_870), ][[5]])
## ------ AOD 1020
#2105
length(data_1.5_c_2017[complete.cases(data_1.5_c_2017$aod_1020), ][[5]])
#2105
length(data_2_c_2017[complete.cases(data_2_c_2017$aod_1020), ][[5]])
complete.cases(data_1.5_c_2017$aod_1020)
regresion <- lm(data_1.5_c_2017[complete.cases(data_1.5_c_2017$aod_1020), ] ~ data_2_c_2017[complete.cases(data_2_c_2017$aod_1020), ])
regresion <- lm((data_1.5_c_2017$aod_1020~ data_2_c_2017$aod_1020)
regresion <- lm(data_1.5_c_2017$aod_1020~ data_2_c_2017$aod_1020)
summary(regresion)
lm(data_1.5_c_2017$aod_380~ data_2_c_2017$aod_380)
regresion <- lm(data_1.5_c_2017$aod_380~ data_2_c_2017$aod_380)
summary(regresion)
length(data_1.5_c_2017$aod_380)
length(data_2_c_2017$aod_380)
regresion <- lm(data_1.5_c_2017$aod_440~ data_2_c_2017$aod_440)
summary(regresion)
regresion <- lm(data_1.5_c_2017$aod_1020~ data_2_c_2017$aod_1020)
summary(regresion)
