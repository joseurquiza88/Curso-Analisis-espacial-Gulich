plot(semiv_exp)
# Ajuste de semivariograma experimetal, con tendencia ####
datos$x <-st_coordinates(datos)[,1]
datos$y <-st_coordinates(datos)[,2]
# Ajuste de semivariograma teórico ####
semiv_teorico <-
fit.variogram(semiv_exp, vgm(c("Exp", "Sph", "Gau")))
# essta funcion perite el ingreso de valores iniciales que supuestamente vi en
# el experimental
plot(semiv_exp, semiv_teorico)
attr(semiv_teorico, 'SSErr')
# el mejor es el exp
semiv_exp
semiv_exp
# essta funcion perite el ingreso de valores iniciales que supuestamente vi en
# el experimental
# me tira el mejor modelo que se ajusta segun suma del cuadrado del error
plot(semiv_exp, semiv_teorico)
attr(semiv_teorico, 'SSErr')
# Generacion de grilla de prediccion ####
limites <-st_read("LimitesCBA/Cordoba_limite.shp")
limites <-st_transform(limites, crs=22174)
plot(limites)
crs(datos)
#otra forma para poner el crs
limites2 <-st_transform(limites, crs=st_crs(datos))
limites2
grilla <- st_bbox(limites) %>%
st_as_stars(dx = 2500) %>%
st_crop(limites)
plot(grilla)
# Kriging Universal ####
# quiero predecir MO
interp_kg <-
krige(MO ~ x + y, datos, grilla, model = semiv_teorico, nmax = 25)
plot(interp_kg["var1.pred"],
main = "Kriging Universal: Predicciones", col = terrain.colors(10))
# La raiz cuadrada de esto seria la desviacion estandar
interp_kg$DE_pred <-sqrt(interp_kg$var1.var)
plot(sqrt(interp_kg["var1.var"]),
main = "Kriging Universal: DE de Prediccion",col = terrain.colors(15))
#  Exportar predichos y varianza de prediccion ####
write_stars(interp_kg,
layer = "var1.pred",
"pred_MO.tiff",
delete_layer = T)
write_stars(interp_kg,
layer = "DE_pred",
"DE_MO.tiff",
delete_layer = T)
# Kriging Regresión ####
names(datos)
# ahora hacemos otra forma, esta vez le agrgams covariables
# Seleccion de covariables
# si ponemos . significa que van tooodas las variables
#predecimos la MO en funcion de la ndvi, twi....
# pero sin considerar la columna geometria
mlreg <- lm(MO ~ ., data = st_drop_geometry(datos))
summary(mlreg)
# ahora vamos a usar metodo para reducir las variables porque son muchas
mlreg_final <- stepAIC(mlreg, direction = "both")
mlreg_final
summary(mlreg_final)
# Incorporamos los residuos del MLR a la base de datos
datos$residuos <- mlreg_final$residuals #parte no explicada por la co-variables
names(datos)
# Ajuste de semivariograma experimetal y teorico a los residuos
# vems la estructura espacial de los residuos
semivariograma_exp_rk <- variogram(residuos ~ 1 , datos)
plot(semivariograma_exp_rk)
semivariograma_exp_rk
semivariograma_teorico_rk <-
fit.variogram(semivariograma_exp_rk , vgm(0.33, c("Sph", "Exp"), 26000, 0.15))
plot(semivariograma_exp_rk , semivariograma_teorico_rk)
#lo mismo sin valores iniciales
semivariograma_teorico_rk <-
fit.variogram(semivariograma_exp_rk , vgm(c("Sph", "Exp")))
plot(semivariograma_exp_rk , semivariograma_teorico_rk)
semivariograma_exp_rk
semivariograma_teorico_rk
# Kriging sobre residuos
grilla_covariables <- read.table("grilla_MO.txt")
head(grilla_covariables)
grilla_covariables <-st_as_sf(grilla_covariables, coords=c("x","y"), crs=22174)
grilla_covariables$x <-st_coordinates(grilla_covariables)[,1]
grilla_covariables$y <-st_coordinates(grilla_covariables)[,2]
kgres <-
krige(residuos ~ 1, datos, grilla_covariables, model = semivariograma_teorico_rk, nmax = 25)
View(grilla_covariables)
# Prediccion final!!!!
# le sumo el krigging de los residuos ==> kgres$var1.pred
grilla_covariables$RK_pred <- predict(mlreg_final, newdata = grilla_covariables) + kgres$var1.pred
st_write(grilla_covariables[,"RK_pred"], "Prediccion_RK.gpkg",delete_layer =T)
# Visualización interectiva de la prediccion ####
grilla_covariables_rast <-st_rasterize(grilla_covariables,dx=500, dy=500)
grilla_covariables_rast
tmap_mode('view')
mapa_prediccion_RK <-
tm_basemap(
c(
Satelite = "Esri.WorldImagery",
Politico = "Esri.WorldGrayCanvas",
Topo = "Esri.WorldTopoMap"
)
) +
tm_shape(grilla_covariables_rast) +
tm_raster(
col="RK_pred",
title = "MO (%)",
style = "quantile",
palette = "YlOrBr",
n = 10
) +
tm_layout(legend.format = list(
scientific = TRUE,
format = "f",
digits = 1
))
mapa_prediccion_RK
library(gstat)
library(spdep)
library(mapview)
library(raster)
library(tmap)
library(leaflet)
library(MASS)
library(e1071)
library(stars)
library(ggplot2)
library(cowplot)
library(caret)
# Carga de base de datos ####
datos <- read.table("MO_Córdoba.txt", header = T)
datos <- st_as_sf(datos, coords = c("x", "y"), crs = 22174)
datos$x <- st_coordinates(datos)[, 1]
datos$y <- st_coordinates(datos)[, 2]
# Random Forest Kriging ####
# Ajuste de modelo de RF
fitControl <- trainControl(method = "cv",number = 10)
# LIBRERIA caret
#cv cross validation, con un k-fold =10
# con esto va a buscar
fitControl <- trainControl(method = "cv",number = 10)
set.seed(7)
train_rf <- train(
MO ~ NDVI + TWI + PPmed + Altura + x + y,
data = datos,
method = "rf",# random forest
trControl = fitControl,
verbose = FALSE,
importance = T
)
fitControl
train_rf
train_rf <- train(
MO ~ NDVI + TWI + PPmed + Altura + x + y,
data = datos,
method = "rf",# random forest
trControl = fitControl,
verbose = FALSE,
importance = T
)
# Importancia de variables
importancia <- as.data.frame(randomForest::importance(train_rf$finalModel))
importancia$Variable <- rownames(importancia)
head(importancia)
ggplot(data = importancia, aes(
x = reorder(Variable, `%IncMSE`),
y = `%IncMSE`,
fill = `%IncMSE`
)) +
labs(x = "Variable", title = "Incremento de MSE (%)") +
geom_col() +
coord_flip() +
theme_bw() +
theme(legend.position = "bottom")
# Incorporamos los residuos del RF a la base de datos
datos$residuosRF <- datos$MO - predict(train_rf, newdata = datos)
# Ajuste de semivariograma experimetal y teorico a los residuos del RF
vrfk <- variogram(residuosRF ~ 1 , datos)
head(importancia)
vrfk <- variogram(residuosRF ~ 1 , datos, cutoff = 150000) # Forzamos el ajuste!!!
plot(vrfk)
vrfk
# es una linea horizonatal recta, no hay correlacion espacial
#a fines didacticos pruebo algunos valores de base
vrfk <- variogram(residuosRF ~ 1 , datos, cutoff = 150000) # Forzamos el ajuste!!!
plot(vrfk)
v.fit_mo_rfk <-
fit.variogram(vrfk , vgm(c("Exp", "Sph","Nug")))
plot(vrfk , v.fit_mo_rfk)
# Kriging sobre residuos del RF
grilla_covariables <- read.table("grilla_MO.txt")
head(grilla_covariables)
grilla_covariables <-
st_as_sf(grilla_covariables,
coords = c("x", "y"),
crs = 22174)
grilla_covariables$x <- st_coordinates(grilla_covariables)[, 1]
grilla_covariables$y <- st_coordinates(grilla_covariables)[, 2]
pred_kg_residuos <-
st_rasterize(kgresRF["var1.pred"],
dx = 500,
dy = 500,
value = NA_real_)
kgresRF <-
krige(residuosRF ~ 1,
datos,
grilla_covariables,
model = v.fit_mo_rfk,
nmax = 25)
plot(pred_kg_residuos,
col = terrain.colors(20),
reset = FALSE)
pred_kg_residuos <-
st_rasterize(kgresRF["var1.pred"],
dx = 500,
dy = 500,
value = NA_real_)
# las dos opciones una le sumamos los resiudis (aunque no suma mucho)
# y la otra opcion es sin los residuos
# Prediccion final
grilla_covariables$RF_pred <-
predict(train_rf, newdata = grilla_covariables) + kgresRF$var1.pred
validacion <- function (fold) {
require(sf)
require(caret)
require(gstat)
require(sp)
# cargamos datos
datos <- read.table("MO_Córdoba.txt", header = T)
datos <- st_as_sf(datos, coords = c("x", "y"), crs = 22174)
datos <- cbind(datos, st_coordinates(datos))
set.seed(7)
datos$id <-
sample(rep(1:10, nrow(datos), length.out = nrow(datos)))
list <- 1:10
prediccion <- data.frame()
testset <- data.frame()
training <- subset(datos, id %in% list[-fold])
testing <- subset(datos, id %in% c(fold))
#####################
# Kriging Universal
train_kg <- training
test_kg <- testing
vario <- variogram(MO ~ X + Y, training)
vario_teorico_Kg <- fit.variogram(vario, vgm(c("Sph", "Exp", "Gau")))
# con testing
KU <- krige(MO ~ X + Y, training, testing, vario_teorico_Kg)
#####################
# Regression Kriging
mlr <- lm(MO ~ NDVI + TWI + PPmed + Altura + X + Y, training)
training$residuos_rk <- mlr$residuals
vario_rk <- variogram(residuos_rk ~ 1, training)
model_rk_kg <- fit.variogram(vario_rk, vgm(c("Sph", "Exp")))
# kriging d elos residuos
test_k <- krige(residuos_rk ~ 1 , training, testing, model_rk_kg)
# predecimos  y le sumaos los residuos
test_rk <- predict(mlr, newdata = testing) + test_k$var1.pred
#############################################
# Random Forest
fitControl <- trainControl(method = "cv", number = 10)
#fitControl <- trainControl(method = "none")
set.seed(7)
rf <- train(
MO ~ NDVI + TWI + PPmed + Altura + X + Y,
data = training,
method = "rf",
trControl = fitControl,
verbose = FALSE
)
## predecimos
test_rf <- predict(rf, newdata = testing)
# Random Forest + Kriging Ordinario
training$residuos_rf <-
training$MO - predict(rf, newdata = training)
vario_rf <- variogram(residuos_rf ~ 1, training)
model_rf_ko <-
fit.variogram(vario_rf, vgm(c("Sph", "Exp", "Gau")))
test_ko <- krige(residuos_rf ~ 1 , training, testing, model_rf_ko)
test_rf_ko <- test_rf + test_ko$var1.pred
# Tabla observados y predichos
testset <- rbind(testset, as.data.frame(testing[, "MO"]))
result <- data.frame(
data.frame(
"x" = testing$X,
"y" = testing$Y,
"k-fold" = fold,
"Observado" = testset[, 1],
"KU" = KU$var1.pred,
"RK" = test_rk,
"RF" = test_rf,
"RF_KO" = test_rf_ko
)
)
return(result)
}
# Correr validacion cruzada
resultados <- do.call(rbind,lapply(1:10, validacion))
# Comparacion de metodos
head(resultados)
tabla <- resultados[, 4:8]
resumen <- function (j) {
ME <- mean(tabla [, j] - tabla[, "Observado"])
MAE <- mean(abs(tabla [, j] - tabla[, "Observado"]))
MAPE <-
mean(abs(tabla [, j] - tabla[, "Observado"]) / tabla[, "Observado"]) *
100
MSE <- mean((tabla [, j] - tabla[, "Observado"]) ^ 2)
RMSE <- sqrt(mean((tabla [, j] - tabla[, "Observado"]) ^ 2))
RMSE_cv <- sqrt(MSE) / mean(tabla[, "Observado"]) * 100
rLM <- lm(tabla [, j] ~ tabla[, "Observado"])
R2 <- as.matrix(summary(rLM)$adj.r.squared)
resumen <-
data.frame("Modelo" = names(tabla [j]), ME, MAE, MAPE, MSE, RMSE, RMSE_cv, R2)
return(resumen)
}
tablafinal <- do.call("rbind", lapply(2:5, resumen))
tablafinal
install.packages("INLA",repos=c(getOption("repos"),INLA="https://inla.r-inla-download.org/R/stable"), dep=TRUE)
install.packages("inlabru")
library(inlabru)
library(graph)
library(Rgraphviz)
install.packages("INLA",repos=c(getOption("repos"),INLA="https://inla.r-inla-download.org/R/stable"), dep=TRUE)
'/usr/bin/cp --help'
/usr/bin/cp --help
--help
library(BiocManager)
install.packages("INLA",repos=c(getOption("repos"),INLA="https://inla.r-inla-download.org/R/stable"), dep=TRUE)
library(INLAspacetime)
## -------------------------------------------------------------------------------------------------------------------------------------------------
#| code-fold: true
#| code-summary: "Carga paquetes y funciones"
library(nlme)
library(dplyr)
library(ggplot2)
library(sf)
library(tmap)
resumir_modelo <- function(modelo) {
rmse <- function(modelo) {
sqrt(mean(modelo$residuals^2))
}
aic <- AIC(modelo)
bic <- BIC(modelo)
my_rmse <- rmse(modelo)
regresora <- paste(attr(modelo$terms,"term.labels"), collapse = ", ")
conCor <- ifelse(length(modelo$modelStruct), 'Si', 'No')
data.frame('Indice' = regresora,
'ConCorr' = conCor,
'AIC' = aic,
'BIC' = bic,
'RMSE' = my_rmse,
check.names = FALSE)
}
diferenciaNormalizada <- function(x, y) {
(x - y) / (x + y)
}
## -------------------------------------------------------------------------------------------------------------------------------------------------
datos <- read.table("data/No_quemadas.txt")
getwd()
## -------------------------------------------------------------------------------------------------------------------------------------------------
setwd("D:/Josefina/Cursos/curso_gulich/analisis_espacial/code/Practico_5")
datos <- read.table("data/No_quemadas.txt")
## -------------------------------------------------------------------------------------------------------------------------------------------------
datos <- datos |>
mutate(
ndvi = diferenciaNormalizada(Banda4, Banda3),
gndvi = diferenciaNormalizada(Banda4, Banda2),
nci = diferenciaNormalizada(Banda5, Banda2)
)
## -------------------------------------------------------------------------------------------------------------------------------------------------
datos_sf <-
sf::st_as_sf(datos,
coords = c('X_coord', 'Y_coord'),
crs = 32720)
tmap_mode('view')
## -------------------------------------------------------------------------------------------------------------------------------------------------
tm_shape(datos_sf) +
tm_dots(fill = 'TCH',
fill.scale = tm_scale_continuous(values = "carto.ag_grn_yl"),
size = 0.5)
## -------------------------------------------------------------------------------------------------------------------------------------------------
# modelo lineal
#variable regresora es el nvdi
# yo quiero predecir TCH
modelo_ndvi <- gls(TCH ~ ndvi,
data = datos,
method = 'REML')
summary(modelo_ndvi)
## -------------------------------------------------------------------------------------------------------------------------------------------------
#| label: fig-gndvi
#| fig-cap: "TCH en función de gNDVI"
#| column: margin
#| echo: true
ggplot(datos, aes(gndvi, TCH)) +
geom_point()
## -------------------------------------------------------------------------------------------------------------------------------------------------
modelo_gndvi <- gls(TCH ~ gndvi,
data = datos,
method = 'REML')
summary(modelo_gndvi)
## -------------------------------------------------------------------------------------------------------------------------------------------------
modelo_nci <-  gls(TCH ~ nci,
data = datos,
method = 'REML')
summary(modelo_nci)
## -------------------------------------------------------------------------------------------------------------------------------------------------
rbind(
resumir_modelo(modelo_ndvi),
resumir_modelo(modelo_gndvi),
resumir_modelo(modelo_nci)
)
modelo_ndvi_conCorr <- gls(
TCH ~ ndvi,
# Igual que antes pero le decimos que los residuos estan correlacionados
# funcion exponencial, considerando x e y
#ajustamos con correlacion espacial
correlation = corExp(
form =  ~ as.numeric(as.character(X_coord)) +
as.numeric(as.character(Y_coord)),
metric = "euclidean",
nugget = FALSE# que no calcule el  nugget, lo ideal es probar con/sin nugget
#cual es el mejor. Cual es la variabilidad a escala menor
),
data = datos,
method = 'REML'
)
summary(modelo_ndvi_conCorr)
## -------------------------------------------------------------------------------------------------------------------------------------------------
#| label: modelo-corr-nci
modelo_nci_conCorr <- gls(
TCH ~ nci,
correlation = corExp(
form =  ~ as.numeric(as.character(X_coord)) +
as.numeric(as.character(Y_coord)),
metric = "euclidean",
nugget = FALSE
),
data = datos,
method = 'REML'
)
summary(modelo_nci_conCorr)
rbind(
resumir_modelo(modelo_ndvi),
resumir_modelo(modelo_ndvi_conCorr),
resumir_modelo(modelo_gndvi),
resumir_modelo(modelo_gndvi_conCorr),
resumir_modelo(modelo_nci),
resumir_modelo(modelo_nci_conCorr)
)
modelo_ndvi_conCorr <- gls(
TCH ~ ndvi,
# Igual que antes pero le decimos que los residuos estan correlacionados
# funcion exponencial, considerando x e y
#ajustamos con correlacion espacial
correlation = corExp(
form =  ~ as.numeric(as.character(X_coord)) +
as.numeric(as.character(Y_coord)),
metric = "euclidean",
nugget = FALSE# que no calcule el  nugget, lo ideal es probar con/sin nugget
#cual es el mejor. Cual es la variabilidad a escala menor
),
data = datos,
method = 'REML'
)
summary(modelo_ndvi_conCorr)
## -------------------------------------------------------------------------------------------------------------------------------------------------
#| label: modelo-corr-gndvi
modelo_gndvi_conCorr <- gls(
TCH ~ gndvi,
correlation = corExp(
form =  ~ as.numeric(as.character(X_coord)) +
as.numeric(as.character(Y_coord)),
metric = "euclidean",
nugget = FALSE
),
data = datos,
method = 'REML'
)
summary(modelo_gndvi_conCorr)
## -------------------------------------------------------------------------------------------------------------------------------------------------
#| label: modelo-corr-nci
modelo_nci_conCorr <- gls(
TCH ~ nci,
correlation = corExp(
form =  ~ as.numeric(as.character(X_coord)) +
as.numeric(as.character(Y_coord)),
metric = "euclidean",
nugget = FALSE
),
data = datos,
method = 'REML'
)
summary(modelo_nci_conCorr)
rbind(
resumir_modelo(modelo_ndvi),
resumir_modelo(modelo_ndvi_conCorr),
resumir_modelo(modelo_gndvi),
resumir_modelo(modelo_gndvi_conCorr),
resumir_modelo(modelo_nci),
resumir_modelo(modelo_nci_conCorr)
)
install.packages(
"INLA",
repos = c(getOption("repos"), INLA = "https://inla.r-inla-download.org/R/testing"),
dep = TRUE
)
options(timeout = 1000)
install.packages("INLA",repos=c(getOption("repos"),INLA="https://inla.r-inla-download.org/R/stable"), dep=TRUE)
options(timeout = 1000)
install.packages("INLA",repos=c(getOption("repos"),INLA="https://inla.r-inla-download.org/R/stable"), dep=TRUE)
